# CardMarket Price Scraper - Anleitung

## ğŸ¯ Zweck
Dieser Scraper lÃ¤dt automatisch die Preise von CardMarket fÃ¼r ein bestimmtes Set.  
**Nur Mid und High Rarity werden gescraped** (Low Rarity zeigt nur Links).

---

## âš™ï¸ Setup

### 1. Chrome Browser installieren
Der Scraper braucht Google Chrome.  
Download: https://www.google.com/chrome/

### 2. ChromeDriver installieren
- Download: https://googlechromelabs.github.io/chrome-for-testing/
- WÃ¤hle die Version die zu deinem Chrome passt
- Entpacke `chromedriver.exe` nach `C:\Windows\` ODER in den Projekt-Ordner
- Alternative: `pip install webdriver-manager` (automatisch)

### 3. Selenium installieren
```bash
.venv\Scripts\activate
pip install selenium
```

---

## ğŸš€ Verwendung

### Schritt 1: Config bearbeiten
Ã–ffne `scraper_config.json` und Ã¤ndere:

```json
{
  "target_set": "ASC",              â† 3-Buchstaben Set-Code
  "target_set_name": "Astral Scarlet",  â† Voller Set-Name
  "rarity_versions_to_scrape": ["2", "3"]  â† Nur Mid (2) und High (3)
}
```

**Wichtige Set-Codes** (aus `all_cards_database.csv`):
- `ASC` = Astral Scarlet
- `MEG` = Mega Evolution
- `PAL` = Paldea
- `SP` = Sword & Shield Promos
- `SVI` = Scarlet & Violet

### Schritt 2: Scraper starten
Doppelklick auf: **`RUN_PRICE_SCRAPER.bat`**

### Schritt 3: Warten
- Der Scraper Ã¶ffnet Chrome Browser
- Geht jede Karte durch (V2 + V3)
- Extrahiert den Preis
- Speichert in `data/cardmarket_prices.csv`

**Geschwindigkeit:**
- ~3-6 Sekunden pro Karte
- ~200 Karten (ASC) = ca. 30-40 Minuten
- Alle 50 Karten: 2 Minuten Pause

### Schritt 4: Browser neu laden
Nach dem Scraper:
- F5 in `landing.html` drÃ¼cken
- Preise sollten nun bei Mid/High Rarity erscheinen

---

## ğŸ“Š Wie es funktioniert

### Versionen:
- **V1 (Low Rarity)**: Common, Uncommon, Rare, Holo  
  â†’ Zeigt nur "ğŸ” CardMarket" Link (kein Preis)

- **V2 (Mid Rarity)**: Ultra Rare, Rainbow Rare  
  â†’ Zeigt "ğŸ’° â‚¬X.XX" wenn gescraped

- **V3 (High Rarity)**: EX, V, VMAX, VSTAR, Special Art  
  â†’ Zeigt "ğŸ’° â‚¬X.XX" wenn gescraped

### Checkpoint-System:
- Fortschritt wird alle 10 Karten gespeichert
- Bei Abbruch (Ctrl+C): Fortschritt bleibt erhalten
- Beim nÃ¤chsten Start: Macht dort weiter

### Log-Dateien:
- `price_scraper.log` - Detailliertes Log
- `scraper_checkpoint.json` - Fortschritt-Checkpoint

---

## ğŸ›  Fehlerbehandlung

### "ChromeDriver not found"
**LÃ¶sung:**
```bash
pip install webdriver-manager
```
Oder manuell ChromeDriver installieren (siehe oben).

### "Error extracting price"
**MÃ¶gliche Ursachen:**
1. CardMarket hat Layout geÃ¤ndert â†’ CSS Selektoren anpassen
2. Bot-Detection â†’ Delays erhÃ¶hen in `scraper_config.json`
3. Karte existiert nicht auf CardMarket

**LÃ¶sung:** Delays erhÃ¶hen:
```json
"delay_min_seconds": 5,
"delay_max_seconds": 10
```

### "TimeoutException"
Seite lÃ¤dt zu langsam.  
**LÃ¶sung:** Internet-Verbindung prÃ¼fen oder Timeout erhÃ¶hen (im Code, Zeile ~120).

### Browser wird von CardMarket blockiert
**LÃ¶sung:**
1. Selenium mit echtem Chrome-Profil nutzen (manuell einloggen)
2. headless: false â†’ Du siehst was passiert
3. LÃ¤ngere Delays (8-12 Sekunden)

---

## âš¡ Performance-Tipps

### Schneller (riskanter):
```json
"delay_min_seconds": 2,
"delay_max_seconds": 4,
"batch_size": 100
```

### Langsamer (sicherer):
```json
"delay_min_seconds": 5,
"delay_max_seconds": 10,
"batch_size": 30,
"batch_pause_minutes": 5
```

### Headless Mode (im Hintergrund):
```json
"headless": true
```
â†’ Schneller, aber siehst nicht was passiert

---

## ğŸ“… WÃ¶chentliche Updates

### Windows Task Scheduler:
1. Task Scheduler Ã¶ffnen
2. "Create Basic Task"
3. Trigger: Weekly (z.B. Sonntag 3:00 Uhr)
4. Action: `RUN_PRICE_SCRAPER.bat`

### Manuell:
Einfach `RUN_PRICE_SCRAPER.bat` einmal pro Woche laufen lassen.

---

## ğŸ“ Dateien Ãœbersicht

| Datei | Zweck |
|-------|-------|
| `scraper_config.json` | Konfiguration (Set, Delays, etc.) |
| `cardmarket_price_scraper.py` | Python Scraper |
| `RUN_PRICE_SCRAPER.bat` | Start-Script |
| `data/cardmarket_prices.csv` | Output mit Preisen |
| `price_scraper.log` | Detailliertes Log |
| `scraper_checkpoint.json` | Fortschritt |

---

## ğŸ” Beispiel-Output

### Vorher (data/cardmarket_prices.csv):
```csv
set,number,name,rarity,version,price_eur,cardmarket_url
ASC,1,Bulbasaur,,2,,"https://www.cardmarket.com/..."
ASC,1,Bulbasaur,,3,,"https://www.cardmarket.com/..."
```

### Nachher:
```csv
set,number,name,rarity,version,price_eur,cardmarket_url
ASC,1,Bulbasaur,,2,0.50,"https://www.cardmarket.com/..."
ASC,1,Bulbasaur,,3,12.99,"https://www.cardmarket.com/..."
```

### Im Browser:
- **Low Rarity**: ğŸ” CardMarket (Link)
- **Mid Rarity**: ğŸ’° â‚¬0.50 (Preis)
- **High Rarity**: ğŸ’° â‚¬12.99 (Preis)

---

## âš ï¸ Wichtige Hinweise

1. **CardMarket Terms of Service beachten**  
   Zu viele Requests = automatische Blockierung mÃ¶glich

2. **Delays nicht zu kurz setzen**  
   Minimum 3 Sekunden zwischen Requests

3. **Checkpoint regelmÃ¤ÃŸig speichern**  
   Bei Absturz kann fortgesetzt werden

4. **Nur aktuelle Sets scrapen**  
   Nicht alle 23.000 URLs auf einmal! (â†’ Ban-Risiko)

5. **Preise aktualisieren sich automatisch**  
   Sobald CSV aktualisiert ist, F5 im Browser drÃ¼cken

---

## ğŸ†˜ Support

Bei Problemen:
1. `price_scraper.log` prÃ¼fen
2. Chrome + ChromeDriver Version checken
3. Internet-Verbindung stabil?
4. CardMarket erreichbar?

---

**Viel Erfolg beim Scrapen! ğŸ´ğŸ’°**
